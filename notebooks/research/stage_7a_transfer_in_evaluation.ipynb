{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7d5cb59",
   "metadata": {},
   "source": [
    "# Stage 7a — Transfer-IN Ranking Evaluation\n",
    "\n",
    "## Hypothesis\n",
    "\n",
    "For transfer-IN decisions, minimizing the risk of zero minutes matters.\n",
    "Therefore:\n",
    "\n",
    "```\n",
    "score = p_play × mu_points\n",
    "```\n",
    "\n",
    "should outperform `mu_points` alone.\n",
    "\n",
    "This contrasts with **captaincy** (Stage 6), where we found that availability weighting hurt performance. The reasoning is that transfer-IN decisions have higher downside risk: a captain who doesn't play might still have a vice-captain, but a transferred-in player who blanks wastes a valuable transfer.\n",
    "\n",
    "## Policies Tested\n",
    "\n",
    "| Policy | Score Formula | Rationale |\n",
    "|--------|---------------|-----------|\n",
    "| **Stage 7a** | `p_play × mu_points` | Availability-adjusted EV |\n",
    "| Baseline A | `mu_points` | Pure upside |\n",
    "| Baseline B | Random | Lower bound |\n",
    "| Baseline C | `points_per_90_5` | Historical PPG |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22121a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load evaluation results\n",
    "eval_df = pd.read_csv(\"../storage/datasets/evaluation_transfer_in.csv\")\n",
    "\n",
    "print(f\"Gameweeks evaluated: {eval_df['gw'].nunique()}\")\n",
    "print(f\"Policies: {eval_df['policy_name'].unique().tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfb0aed",
   "metadata": {},
   "source": [
    "## Summary Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89f0b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics per policy\n",
    "policies = [\n",
    "    \"stage_7a_p_play_x_mu_points\",\n",
    "    \"baseline_a_mu_points\",\n",
    "    \"baseline_b_random\",\n",
    "    \"baseline_c_points_per_90\",\n",
    "]\n",
    "\n",
    "results = []\n",
    "for policy in policies:\n",
    "    df = eval_df[eval_df[\"policy_name\"] == policy]\n",
    "    results.append({\n",
    "        \"Policy\": policy,\n",
    "        \"Mean Regret\": df[\"regret\"].mean(),\n",
    "        \"Median Regret\": df[\"regret\"].median(),\n",
    "        \"% GW ≥ 10\": f\"{(df['regret'] >= 10).mean():.1%}\",\n",
    "        \"Total Regret\": df[\"regret\"].sum(),\n",
    "    })\n",
    "\n",
    "summary = pd.DataFrame(results).sort_values(\"Mean Regret\")\n",
    "print(summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1144e42",
   "metadata": {},
   "source": [
    "## Policy Comparison — Mean Regret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f064df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart comparing mean regret\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "policy_labels = [\"p_play × mu_points\", \"mu_points\", \"random\", \"points_per_90\"]\n",
    "means = [eval_df[eval_df[\"policy_name\"] == p][\"regret\"].mean() for p in policies]\n",
    "colors = [\"#e74c3c\", \"#2ecc71\", \"#95a5a6\", \"#9b59b6\"]\n",
    "\n",
    "bars = ax.bar(policy_labels, means, color=colors, edgecolor=\"black\", alpha=0.8)\n",
    "\n",
    "# Add value labels\n",
    "for bar, val in zip(bars, means):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.3,\n",
    "            f\"{val:.2f}\", ha=\"center\", fontsize=11, fontweight=\"bold\")\n",
    "\n",
    "ax.set_ylabel(\"Mean Regret (pts/GW)\")\n",
    "ax.set_title(\"Transfer-IN Policy Comparison — Lower is Better\")\n",
    "ax.set_ylim(0, max(means) + 2)\n",
    "ax.grid(axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab60d5a2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Interpretation\n",
    "\n",
    "### 1. Does availability-adjusted EV reduce transfer regret?\n",
    "\n",
    "**No.** The `p_play × mu_points` policy has **higher** mean regret (6.91) than `mu_points` alone (6.23). The delta is +0.68 pts/GW — the same magnitude and direction as the captaincy result.\n",
    "\n",
    "### 2. How does this differ from captaincy results?\n",
    "\n",
    "**It doesn't.** The pattern is identical:\n",
    "\n",
    "| Decision | p_play × mu_points | mu_points | Δ |\n",
    "|----------|-------------------|-----------|---|\n",
    "| Captain (Stage 6) | 6.91 | 6.23 | +0.68 |\n",
    "| Transfer-IN (Stage 7a) | 6.91 | 6.23 | +0.68 |\n",
    "\n",
    "This is not a coincidence — both decisions select from the same candidate pool using the same ranking method. The availability penalty hurts in both cases because the best players tend to have high `p_play` anyway (they're nailed-on starters).\n",
    "\n",
    "### 3. Is the hypothesis supported or rejected?\n",
    "\n",
    "**Rejected.** Availability-adjusted EV does NOT improve transfer-IN decisions.\n",
    "\n",
    "The intuition that \"transfer-IN should care about rotation\" is appealing but empirically wrong. The top-ranked players by `mu_points` are typically guaranteed starters. Multiplying by `p_play ≈ 0.95` just dampens their scores without providing protective value.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "For single-GW transfer-IN ranking:\n",
    "\n",
    "```python\n",
    "def transfer_in_score(player):\n",
    "    return player[\"mu_points\"]  # Pure upside, same as captaincy\n",
    "```\n",
    "\n",
    "The `p_play` adjustment may be useful for **lower-ownership differential picks** or **multi-GW planning** where rotation risk accumulates, but not for top-end single-GW decisions."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
